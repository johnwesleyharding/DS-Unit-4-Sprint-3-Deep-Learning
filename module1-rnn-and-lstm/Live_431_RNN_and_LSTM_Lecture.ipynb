{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_IizNKWLomoA"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Lesson 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "## _aka_ PREDICTING THE FUTURE!\n",
    "\n",
    "<img src=\"https://media.giphy.com/media/l2JJu8U8SoHhQEnoQ/giphy.gif\" width=480 height=356>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "> \"Yesterday's just a memory - tomorrow is never what it's supposed to be.\" -- Bob Dylan\n",
    "\n",
    "Wish you could save [Time In A Bottle](https://www.youtube.com/watch?v=AnWWj6xOleY)? With statistics you can do the next best thing - understand how data varies over time (or any sequential order), and use the order/time dimension predictively.\n",
    "\n",
    "A sequence is just any enumerated collection - order counts, and repetition is allowed. Python lists are a good elemental example - `[1, 2, 2, -1]` is a valid list, and is different from `[1, 2, -1, 2]`. The data structures we tend to use (e.g. NumPy arrays) are often built on this fundamental structure.\n",
    "\n",
    "A time series is data where you have not just the order but some actual continuous marker for where they lie \"in time\" - this could be a date, a timestamp, [Unix time](https://en.wikipedia.org/wiki/Unix_time), or something else. All time series are also sequences, and for some techniques you may just consider their order and not \"how far apart\" the entries are (if you have particularly consistent data collected at regular intervals it may not matter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44QZgrPUe3-Y"
   },
   "source": [
    "## Recurrent Neural Networks\n",
    "\n",
    "There's plenty more to \"traditional\" time series, but the latest and greatest technique for sequence data is recurrent neural networks. A recurrence relation in math is an equation that uses recursion to define a sequence - a famous example is the Fibonacci numbers:\n",
    "\n",
    "$F_n = F_{n-1} + F_{n-2}$\n",
    "\n",
    "For formal math you also need a base case $F_0=1, F_1=1$, and then the rest builds from there. But for neural networks what we're really talking about are loops:\n",
    "\n",
    "![Recurrent neural network](https://upload.wikimedia.org/wikipedia/commons/b/b5/Recurrent_neural_network_unfold.svg)\n",
    "\n",
    "The hidden layers have edges (output) going back to their own input - this loop means that for any time `t` the training is at least partly based on the output from time `t-1`. The entire network is being represented on the left, and you can unfold the network explicitly to see how it behaves at any given `t`.\n",
    "\n",
    "Different units can have this \"loop\", but a particularly successful one is the long short-term memory unit (LSTM):\n",
    "\n",
    "![Long short-term memory unit](https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Long_Short-Term_Memory.svg/1024px-Long_Short-Term_Memory.svg.png)\n",
    "\n",
    "There's a lot going on here - in a nutshell, the calculus still works out and backpropagation can still be implemented. The advantage (ane namesake) of LSTM is that it can generally put more weight on recent (short-term) events while not completely losing older (long-term) information.\n",
    "\n",
    "After enough iterations, a typical neural network will start calculating prior gradients that are so small they effectively become zero - this is the [vanishing gradient problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem), and is what RNN with LSTM addresses. Pay special attention to the $c_t$ parameters and how they pass through the unit to get an intuition for how this problem is solved.\n",
    "\n",
    "So why are these cool? One particularly compelling application is actually not time series but language modeling - language is inherently ordered data (letters/words go one after another, and the order *matters*). [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) is a famous and worth reading blog post on this topic.\n",
    "\n",
    "For our purposes, let's use TensorFlow and Keras to train RNNs with natural language. Resources:\n",
    "\n",
    "- https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py\n",
    "- https://keras.io/layers/recurrent/#lstm\n",
    "- http://adventuresinmachinelearning.com/keras-lstm-tutorial/\n",
    "\n",
    "Note that `tensorflow.contrib` [also has an implementation of RNN/LSTM](https://www.tensorflow.org/tutorials/sequences/recurrent)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eWrQllf8WEd-"
   },
   "source": [
    "### RNN/LSTM Sentiment Classification with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 975
    },
    "colab_type": "code",
    "id": "Ti23G0gRe3kr",
    "outputId": "bba9ae40-a286-49ed-d87b-b2946fb60ddf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Anaconda3\\envs\\U4-S2-NN\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\John\\Anaconda3\\envs\\U4-S2-NN\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\John\\Anaconda3\\envs\\U4-S2-NN\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\John\\Anaconda3\\envs\\U4-S2-NN\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\John\\Anaconda3\\envs\\U4-S2-NN\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\John\\Anaconda3\\envs\\U4-S2-NN\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\John\\Anaconda3\\envs\\U4-S2-NN\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\John\\Anaconda3\\envs\\U4-S2-NN\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\John\\Anaconda3\\envs\\U4-S2-NN\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\John\\Anaconda3\\envs\\U4-S2-NN\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\John\\Anaconda3\\envs\\U4-S2-NN\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\John\\Anaconda3\\envs\\U4-S2-NN\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Trains an LSTM model on the IMDB sentiment classification task.\n",
    "The dataset is actually too small for LSTM to be of any advantage\n",
    "compared to simpler, much faster methods such as TF-IDF + LogReg.\n",
    "**Notes**\n",
    "- RNNs are tricky. Choice of batch size is important,\n",
    "choice of loss and optimizer is critical, etc.\n",
    "Some configurations won't converge.\n",
    "- LSTM loss decrease patterns during training can be quite different\n",
    "from what you see with CNNs/MLPs/etc.\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "max_features = 20000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 80\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[2467])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 975
    },
    "colab_type": "code",
    "id": "Ti23G0gRe3kr",
    "outputId": "bba9ae40-a286-49ed-d87b-b2946fb60ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 80)\n",
      "x_test shape: (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   15,   256,     4,     2,     7,  3766,     5,   723,    36,\n",
       "          71,    43,   530,   476,    26,   400,   317,    46,     7,\n",
       "           4, 12118,  1029,    13,   104,    88,     4,   381,    15,\n",
       "         297,    98,    32,  2071,    56,    26,   141,     6,   194,\n",
       "        7486,    18,     4,   226,    22,    21,   134,   476,    26,\n",
       "         480,     5,   144,    30,  5535,    18,    51,    36,    28,\n",
       "         224,    92,    25,   104,     4,   226,    65,    16,    38,\n",
       "        1334,    88,    12,    16,   283,     5,    16,  4472,   113,\n",
       "         103,    32,    15,    16,  5345,    19,   178,    32])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 975
    },
    "colab_type": "code",
    "id": "Ti23G0gRe3kr",
    "outputId": "bba9ae40-a286-49ed-d87b-b2946fb60ddf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0127 13:30:25.680789  3400 deprecation.py:506] From C:\\Users\\John\\Anaconda3\\envs\\U4-S2-NN\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0127 13:30:25.696773  3400 deprecation.py:506] From C:\\Users\\John\\Anaconda3\\envs\\U4-S2-NN\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0127 13:30:25.962699  3400 deprecation.py:323] From C:\\Users\\John\\Anaconda3\\envs\\U4-S2-NN\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/15\n",
      "25000/25000 [==============================] - 85s 3ms/sample - loss: 0.4661 - acc: 0.7777 - val_loss: 0.4681 - val_acc: 0.8182\n",
      "Epoch 2/15\n",
      "25000/25000 [==============================] - 84s 3ms/sample - loss: 0.2991 - acc: 0.8783 - val_loss: 0.3975 - val_acc: 0.8201\n",
      "Epoch 3/15\n",
      "25000/25000 [==============================] - 86s 3ms/sample - loss: 0.2127 - acc: 0.9170 - val_loss: 0.4290 - val_acc: 0.8317\n",
      "Epoch 4/15\n",
      "25000/25000 [==============================] - 85s 3ms/sample - loss: 0.1446 - acc: 0.9458 - val_loss: 0.6126 - val_acc: 0.8264\n",
      "Epoch 5/15\n",
      "25000/25000 [==============================] - 85s 3ms/sample - loss: 0.1097 - acc: 0.9604 - val_loss: 0.5511 - val_acc: 0.7950\n",
      "Epoch 6/15\n",
      "25000/25000 [==============================] - 86s 3ms/sample - loss: 0.0764 - acc: 0.9726 - val_loss: 0.6349 - val_acc: 0.8132\n",
      "Epoch 7/15\n",
      "25000/25000 [==============================] - 85s 3ms/sample - loss: 0.0586 - acc: 0.9803 - val_loss: 0.6744 - val_acc: 0.8096\n",
      "Epoch 8/15\n",
      "25000/25000 [==============================] - 86s 3ms/sample - loss: 0.0431 - acc: 0.9857 - val_loss: 0.7332 - val_acc: 0.8119\n",
      "Epoch 9/15\n",
      "25000/25000 [==============================] - 85s 3ms/sample - loss: 0.0362 - acc: 0.9885 - val_loss: 0.8505 - val_acc: 0.8174\n",
      "Epoch 10/15\n",
      "25000/25000 [==============================] - 85s 3ms/sample - loss: 0.0232 - acc: 0.9929 - val_loss: 0.9891 - val_acc: 0.8131\n",
      "Epoch 11/15\n",
      "25000/25000 [==============================] - 80s 3ms/sample - loss: 0.0196 - acc: 0.9937 - val_loss: 0.9174 - val_acc: 0.8033\n",
      "Epoch 12/15\n",
      "25000/25000 [==============================] - 80s 3ms/sample - loss: 0.0166 - acc: 0.9949 - val_loss: 1.0740 - val_acc: 0.8008\n",
      "Epoch 13/15\n",
      "25000/25000 [==============================] - 80s 3ms/sample - loss: 0.0168 - acc: 0.9944 - val_loss: 0.9571 - val_acc: 0.8097\n",
      "Epoch 14/15\n",
      "25000/25000 [==============================] - 84s 3ms/sample - loss: 0.0170 - acc: 0.9952 - val_loss: 0.9867 - val_acc: 0.8092\n",
      "Epoch 15/15\n",
      "25000/25000 [==============================] - 84s 3ms/sample - loss: 0.0135 - acc: 0.9957 - val_loss: 1.0576 - val_acc: 0.8101\n",
      "25000/25000 [==============================] - 10s 396us/sample - loss: 1.0576 - acc: 0.8101\n",
      "Test score: 1.0576279579913617\n",
      "Test accuracy: 0.81012\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=15,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7pETWPIe362y"
   },
   "source": [
    "### LSTM Text generation with Keras\n",
    "\n",
    "What else can we do with LSTMs? Since we're analyzing the *sequence*, we can do more than classify - we can *generate* text. I'ved pulled some news stories using [newspaper](https://github.com/codelucas/newspaper/).\n",
    "\n",
    "This example is drawn from the Keras [documentation](https://keras.io/examples/lstm_text_generation/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = os.listdir('./articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Data\n",
    "\n",
    "data = []\n",
    "\n",
    "for file in data_files:\n",
    "    if file[-3:] == 'txt':\n",
    "        with open(f'./articles/{file}', 'r', errors='ignore') as f:\n",
    "            data.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Data as Chars\n",
    "\n",
    "text = \" \".join(data)\n",
    "\n",
    "chars = list(set(text))\n",
    "\n",
    "char_int = {c:i for i,c in enumerate(chars)}\n",
    "int_char = {i:c for i,c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences: 180776\n"
     ]
    }
   ],
   "source": [
    "# Create the Sequence Data\n",
    "\n",
    "maxlen = 40\n",
    "step = 5\n",
    "\n",
    "encoded = [char_int[c] for c in text]\n",
    "\n",
    "sequences = [] # Each element is 40 characters long\n",
    "next_chars = [] # One element for each sequence\n",
    "\n",
    "for i in range(0, len(encoded) - maxlen, step):\n",
    "    sequences.append(encoded[i : i + maxlen])\n",
    "    next_chars.append(encoded[i + maxlen])\n",
    "    \n",
    "print('sequences:', len(sequences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify x & y\n",
    "\n",
    "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[i,t,char] = 1\n",
    "        \n",
    "    y[i, next_chars[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180776, 40, 121)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180776, 121)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model: a single LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    \n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "    \n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    \n",
    "    generated = ''\n",
    "    \n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    \n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "    \n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_int[char]] = 1\n",
    "            \n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds, temperature=1.0)\n",
    "        next_char = int_char[next_index]\n",
    "        \n",
    "        sentence = sentence[1:] + next_char\n",
    "        \n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()\n",
    "\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def on_epoch_end(epoch, _):\n",
    "#     # Function invoked at end of each epoch. Prints generated text.\n",
    "#     print()\n",
    "#     print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "#     start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "#     for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "#         print('----- diversity:', diversity)\n",
    "\n",
    "#         generated = ''\n",
    "#         sentence = text[start_index: start_index + maxlen]\n",
    "#         generated += sentence\n",
    "#         print('----- Generating with seed: \"' + sentence + '\"')\n",
    "#         sys.stdout.write(generated)\n",
    "\n",
    "#         for i in range(400):\n",
    "#             x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "#             for t, char in enumerate(sentence):\n",
    "#                 x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "#             preds = model.predict(x_pred, verbose=0)[0]\n",
    "#             next_index = sample(preds, diversity)\n",
    "#             next_char = indices_char[next_index]\n",
    "\n",
    "#             sentence = sentence[1:] + next_char\n",
    "\n",
    "#             sys.stdout.write(next_char)\n",
    "#             sys.stdout.flush()\n",
    "#         print()\n",
    "\n",
    "# print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "180608/180776 [============================>.] - ETA: 0s - loss: 2.8258\n",
      "----- Generating text after Epoch: 0\n",
      "----- Generating with seed: \"nt to get a sense of the coherence of Tr\"\n",
      "nt to get a sense of the coherence of Trsthe jreud eutg pelcoN tily taleddnd pufyas wise seatha do ked  fsinet Theg asel wone in Sns name Souns ung bfthl quter boe bos  nlipes at astx Dcstitg titard in wedtet) â€œthe sifmed LhsdechGPbete pbokitr cars hCd, Tha.d ongannti. the Mpaunle rerbice widese why Ksidf, the  ok s3se neant onsangWe Sampserdqs lepy anm ges ous innD onm, al an Sinasâ€™s te sine Jadas T ilonq,thew PA, skeeto bins las a\n",
      "180776/180776 [==============================] - 74s 407us/sample - loss: 2.8257\n",
      "Epoch 2/20\n",
      "180736/180776 [============================>.] - ETA: 0s - loss: 2.3857\n",
      "----- Generating text after Epoch: 1\n",
      "----- Generating with seed: \"are even casually acquainted with the co\"\n",
      "are even casually acquainted with the corcem-nen.\n",
      "\n",
      "But ar this gony. Aly whe inderise foy howhathich jod, walls padee.\n",
      "\n",
      "The wor poppeim to ciserioday te Runta rinor enilider sry Sdoa has tat tirs bepkealiled ndiattoth/Wily Disiosed and ot hhatecroces zod the soaky Fovalciond of cecpuspeonean:\n",
      "\n",
      "â€œRrakkind afles Jreice croatpl)d, On Mathice yracred hias Adoorle ta' ther that foke on, wedet til0-ored.deted simyics withe deanangecas igs ba\n",
      "180776/180776 [==============================] - 74s 409us/sample - loss: 2.3857\n",
      "Epoch 3/20\n",
      "180608/180776 [============================>.] - ETA: 0s - loss: 2.2589\n",
      "----- Generating text after Epoch: 2\n",
      "----- Generating with seed: \"es has been caught between Turkey, a NAT\"\n",
      "es has been caught between Turkey, a NAT9VSLEG, the thar 122kis an douly Cartame to papawerg and pninues wautalk th whe sanstientIs purtoo hin Manthe thol ofer tracretseates dacrlang promes saks arderchisas bad to movar hivy werd on a eart,odit to kas Hist cand fpat 2€ 0empars thes or than hen bes !ghitem te in ther Uridmen the senont broill Ewrering, ath Ban Cousped the ias resiocse, at ham madivea was rntter Gan thes romt Inn, Twabte \n",
      "180776/180776 [==============================] - 73s 404us/sample - loss: 2.2588\n",
      "Epoch 4/20\n",
      "180736/180776 [============================>.] - ETA: 0s - loss: 2.1792\n",
      "----- Generating text after Epoch: 3\n",
      "----- Generating with seed: \"many Republicans â€” say otherwise. And \"\n",
      "many Republicans â€” say otherwise. And ghe slamed ycablite ant greais the wouthoreal), anoâ€™t â€œyouts your and enpors it tre Lart on platien for plool 6 sheithors congegen â€œvolly, offanom) if meid ato trap ofcrastible artherstore sime tho Grestoncy siovided mo¦ld wen itthed betâ€ har us micly of the che to moprcis the â€” eude thay wusthy Prein thed cone follle whit to mpoutyarides dnoo jolly. Shinnes, oud fateral at ound, that hap\n",
      "180776/180776 [==============================] - 73s 407us/sample - loss: 2.1792\n",
      "Epoch 5/20\n",
      "180608/180776 [============================>.] - ETA: 0s - loss: 2.1198\n",
      "----- Generating text after Epoch: 4\n",
      "----- Generating with seed: \"their customers to be upfront about the \"\n",
      "their customers to be upfront about the porice Monmint preedcnies, the cort of chirnt as reefire and prebake in ch'id the mavte adtom thill pering the realines and curlizeb his net as are reit for theppernecine Trovery. Bus on mo caDeswing any hither. Scar a lan poblal or ase reanntiol of the fromuss oo tafe Wistice, furt his lates are thut creads intighen furt, Ukritbess Brol areming amporlentans to Well.\n",
      "\n",
      "u terion our tor eroollete in\n",
      "180776/180776 [==============================] - 73s 406us/sample - loss: 2.1197\n",
      "Epoch 6/20\n",
      "180736/180776 [============================>.] - ETA: 0s - loss: 2.0704\n",
      "----- Generating text after Epoch: 5\n",
      "----- Generating with seed: \"e middle of a barren California desert.\n",
      "\"\n",
      "e middle of a barren California desert.\n",
      "\n",
      "AD. Matremâ€™s wath is do craspotlings promo on with a millice proond wnishe, dit. Prew. F stomerrots ouse sixess unday day to ho las, sconcellore of theâ€™s cackied thew pea streases anlistecrones ard cammssiont, and incoud in te ame the tien acher Ho prosis dive steat sochiel more â€” psaiming his relley nevedive termintsy the cemusionle intormed of tareerts inscedered aprosed the Nesparty rask\n",
      "180776/180776 [==============================] - 73s 406us/sample - loss: 2.0704\n",
      "Epoch 7/20\n",
      "180736/180776 [============================>.] - ETA: 0s - loss: 2.0285\n",
      "----- Generating text after Epoch: 6\n",
      "----- Generating with seed: \"is reliable votes after 21 Conservative \"\n",
      "is reliable votes after 21 Conservative Preyscenâ€™s regeatiows.\n",
      "\n",
      "South: Thid, bllay lagher Ftory a piartmrach a suld thes. Hyer morrizes in thankurs.\n",
      "\n",
      "AD\n",
      "\n",
      "Sanions to a 12 stometion.\n",
      "\n",
      "Ste rermbtist arridifâ€™s hind to to ther their flonen my ciplifbionseays bevertletey. But honk 1650 and Tere staty: Bur grally and his penins of thill phowed as chiming his wangems andon.â€\n",
      "\n",
      "Sexp sist.\n",
      "\n",
      "wi. Trump honâ€™s severation planfer to hern tor mol\n",
      "180776/180776 [==============================] - 74s 408us/sample - loss: 2.0285\n",
      "Epoch 8/20\n",
      "180608/180776 [============================>.] - ETA: 0s - loss: 1.9902\n",
      "----- Generating text after Epoch: 7\n",
      "----- Generating with seed: \"ed wet bedding and made their mom her ki\"\n",
      "ed wet bedding and made their mom her ki. â€œ20 a suse whete logated of is alloss pait the enging and bettine the redistite proplrsionalion lexiciatidionom. Mud.â€\n",
      "\n",
      "Wher and yould werrewed a moond, in 2014, hif chreed his seserealurl seefly of the provi\n",
      "\n",
      "\n",
      "â€œ$38 fforment thor aim Coumâ€™r tame and ferped.\n",
      "\n",
      "2020 andertionsion tho gailly of thy pacom dut.\n",
      "\n",
      "Anvied lowere her the warker ho pent, the reaken to to pelt whet readbotstat from o\n",
      "180776/180776 [==============================] - 74s 411us/sample - loss: 1.9901\n",
      "Epoch 9/20\n",
      "180736/180776 [============================>.] - ETA: 0s - loss: 1.9561\n",
      "----- Generating text after Epoch: 8\n",
      "----- Generating with seed: \"on Schiffâ€™s fate, which she acknowledg\"\n",
      "on Schiffâ€™s fate, which she acknowledget. Chingen not hely, chatiegrat in Syeitible shoogh beca deangy 155 if Fore prostitatianis.â€\n",
      "\n",
      "The wathâ€™â€™s olldy woren yirgatatle tha â€œAny beanss oum the 14test on nating to the remmatyly for cunress0pss oo may coldertien carement resubind just pintered two cable is touteint for grated traising iversidiss posins offly mintary sterify spodingle about to wete, ats appessed and thes nowh, gut \n",
      "180776/180776 [==============================] - 75s 417us/sample - loss: 1.9560\n",
      "Epoch 10/20\n",
      "180736/180776 [============================>.] - ETA: 0s - loss: 1.9249\n",
      "----- Generating text after Epoch: 9\n",
      "----- Generating with seed: \"ty over the years, among other issues. D\"\n",
      "ty over the years, among other issues. De ay the just frog the yeO Sevilem.â€\n",
      "\n",
      "Turked and ay, our trumploskay nettag inatge troode hur soortly and our iverice and to puldia art Rillocincandan, Bâ€™bel Settinse, Retenss mowate, the sup he regiteat, and hilk out a you sontemâ€™s cabory, aftrestom, closwotlally purting the dodoned only U.SBires: (1-4 thie he sist. Yatome For I kelatharated Amorges, Flise an Frolald Ponresp.n.)â€) inctomban\n",
      "180776/180776 [==============================] - 75s 413us/sample - loss: 1.9249\n",
      "Epoch 11/20\n",
      "180736/180776 [============================>.] - ETA: 0s - loss: 1.8955\n",
      "----- Generating text after Epoch: 10\n",
      "----- Generating with seed: \"t new: â€œmy generals and my military,â€\"\n",
      "t new: â€œmy generals and my military,â€ Milwint nasts, if-uming say thour said Sanise pouttob ay or by the flase Werronm tatory tho have counderrs and that Thed-Res\n",
      "\n",
      "-forgates Cwases ritogn hare intated that you gove woven a getermenter and Tound-Fater and a cappoont.â€\n",
      "\n",
      "But in trrate sectonder con fon respolic of Jone sphore two of a cimriovings in the valilativationoun fert, add add stat a peen name the staifine the strowce the siffi\n",
      "180776/180776 [==============================] - 76s 422us/sample - loss: 1.8956\n",
      "Epoch 12/20\n",
      "180736/180776 [============================>.] - ETA: 0s - loss: 1.8684\n",
      "----- Generating text after Epoch: 11\n",
      "----- Generating with seed: \" asking the Ukrainian president to inves\"\n",
      " asking the Ukrainian president to investing ainmol as for Peblons Afforos and the cing of bight whine wans over sobment.\n",
      "\n",
      "[MB. shrilâ€ has and tyra â€” proson\n",
      "\n",
      "En Clanber Het this prost about qaids-ssiping exply rase, shims â€” a hays theals rement mose the gembel piteage docatelâ€™s is â€” morall. -o bat moyI Illay,â€ Ovir Shotoker, juss not in yaid. . Trum amentvich killeâ€™s crapfe, they han flod and I and choch of cass afters flots\n",
      "180776/180776 [==============================] - 77s 429us/sample - loss: 1.8684\n",
      "Epoch 13/20\n",
      "180736/180776 [============================>.] - ETA: 0s - loss: 1.8444\n",
      "----- Generating text after Epoch: 12\n",
      "----- Generating with seed: \"ight against the Islamic State.\n",
      "\n",
      "But exp\"\n",
      "ight against the Islamic State.\n",
      "\n",
      "But expent molins of sidners, an Buck book].â€ Senatiatlishts vooot of lastbored Tr-Atyâ€™s actions lyondont inteaties whicks.\n",
      "\n",
      "Dalyed Mard Prarered Colpasding you neerthing it that Wy. Hol/FleamabIâ€™m Stife the ligrter, earies and nit, theyirald of enter, â€œFlooblace reawned the ourn with his wele thine everybur to exen inlinged for arQ ave early ring of my tapere mopement?\n",
      "\n",
      "As I.â€ Aftime to feced be\n",
      "180776/180776 [==============================] - 76s 421us/sample - loss: 1.8444\n",
      "Epoch 14/20\n",
      "180736/180776 [============================>.] - ETA: 0s - loss: 1.8214\n",
      "----- Generating text after Epoch: 13\n",
      "----- Generating with seed: \"al border, negotiated by the two states,\"\n",
      "al border, negotiated by the two states, for Mamical, be homen for keage to says.\n",
      "\n",
      "A brow durophistes be the outing freallightir â€œitcligttaro breaks. The Wabrec have incillatizel was spigntary poblited but ofliser throws ard to lest alse fach luicing of nearo-leas, about thes, Lerven we stacusitail, deprest for a Sunvised the ulien ageation restran been soom [ware you gee on out of eepalk in persogmatis to your in AmmeLiF reavor Oft N\n",
      "180776/180776 [==============================] - 77s 425us/sample - loss: 1.8214\n",
      "Epoch 15/20\n",
      "180736/180776 [============================>.] - ETA: 0s - loss: 1.8001\n",
      "----- Generating text after Epoch: 14\n",
      "----- Generating with seed: \"e United Statesâ€™ allies as nonchalantl\"\n",
      "e United Statesâ€™ allies as nonchalantly loin and dilf.\n",
      "\n",
      "Raid invisimetion dedi wars: 20 poriser.\n",
      "\n",
      "He gurt. (Scedinivainsl Cazor intoungy, out with Gourn (D. When Leeson Bil Desonerono.â€\n",
      "\n",
      "Ho White Here then youd accover in they courd of a age the 1999 house dincesold:â€ Distive concaiced face, whele the cart. One pervasity Ruporias inveded atâ€™s night bathin out ond areativation issigrime Nurltiake You touthss; (th. Athilles arrickno\n",
      "180776/180776 [==============================] - 75s 418us/sample - loss: 1.8003\n",
      "Epoch 16/20\n",
      "180736/180776 [============================>.] - ETA: 0s - loss: 1.7810\n",
      "----- Generating text after Epoch: 15\n",
      "----- Generating with seed: \"anged. Minecraft remains a massive sandb\"\n",
      "anged. Minecraft remains a massive sandbord.\n",
      "\n",
      "The midenge of would a proverwing to hosugh Axence. The cratif mo shripsed by a her feem killed edcore whill camogi sporch arequiser juch cal offerved a said. Fre â€œhow!â€ Han Sieveâ€™s Sechow,â€ he the year working exclutic assoold and caph.\n",
      "\n",
      "SeDv-Fisty Ithen 20050 gegate formen president. Jum\n",
      "\n",
      "Overgaine to was Resking the supplakey you surd. It a station. For the wawing the Rip to be. Lem\n",
      "180776/180776 [==============================] - 74s 409us/sample - loss: 1.7810\n",
      "Epoch 17/20\n",
      "180608/180776 [============================>.] - ETA: 0s - loss: 1.7621\n",
      "----- Generating text after Epoch: 16\n",
      "----- Generating with seed: \"h publicly and behind the scenes.\n",
      "\n",
      "Admin\"\n",
      "h publicly and behind the scenes.\n",
      "\n",
      "Admintion us a fict 11: Atwared Sucher Anoona knotwer Kurdmy (D-twallring ehasthore hil wal fightâ€™s and sound-momble of forsal. It with Huspon Suspon\n",
      "\n",
      "Durny â€” ind, incides.\n",
      "\n",
      "Moniayportions.\n",
      "\n",
      "The ved for book Eadien to be a blater were our a pase it the allowitions from that has visorsing for can to aroncasezy.\n",
      "\n",
      "Cawdact Trump has by procesed to whow reterned be all entthaugue destigemend. But that s\n",
      "180776/180776 [==============================] - 74s 409us/sample - loss: 1.7619\n",
      "Epoch 18/20\n",
      "180736/180776 [============================>.] - ETA: 0s - loss: 1.7438\n",
      "----- Generating text after Epoch: 17\n",
      "----- Generating with seed: \"rganizations and (on at least one occasi\"\n",
      "rganizations and (on at least one occasitia some divide to ans, was nownâ€™t Terus.\n",
      "\n",
      "A, Nonellying and Choine Slear-erllagentting that a got was not had Sund. The said, he was has fordey Ukneed aroclly incrup, will contribiog to he belavitize inctainatemel that he hust clause ongs has.\n",
      "\n",
      "\n",
      "\n",
      "Andersions, it sear probeationse in a revereint sayicam exter by the Lindvion, of allibators â€œsaye as it you and comestimes formoniun intergociss of\n",
      "180776/180776 [==============================] - 74s 409us/sample - loss: 1.7438\n",
      "Epoch 19/20\n",
      "180608/180776 [============================>.] - ETA: 0s - loss: 1.7274\n",
      "----- Generating text after Epoch: 18\n",
      "----- Generating with seed: \"this long-standing law to ensure those s\"\n",
      "this long-standing law to ensure those seased agent sway that was hamplein progugent making samestiguting bearse is ploskers. Out im. The Deppurtiating cutulled Trump is expeecorue thisâ€™s your wither diphers in 26-015 trenst other a 35 seom at fust man al officalling.\n",
      "\n",
      "A states and hearing can an the citturs in a se hoshane her action dantedston not thish got careprablorion, and Frimbal onlent dire omelales to the gom the decesper thr\n",
      "180776/180776 [==============================] - 74s 408us/sample - loss: 1.7277\n",
      "Epoch 20/20\n",
      "180736/180776 [============================>.] - ETA: 0s - loss: 1.7126\n",
      "----- Generating text after Epoch: 19\n",
      "----- Generating with seed: \". 10. (Jabin Botsford/The Washington Pos\"\n",
      ". 10. (Jabin Botsford/The Washington Post M.. of the violent caticilate faim while ad of the gived.â€\n",
      "\n",
      "Oc the tlating and all two persay to be a day 1 smarever the tompout to 20 18 stacefe Sandinaty upe. But sould accear to good Buther Jase going, hay backet, 20 perceived,â€ Mandis 1420, fent. You led that youse rate persciot from the poses thinds on thround communtion, sut aif and now shoost to prove deplased, ans tamen with-redsised p\n",
      "180776/180776 [==============================] - 74s 409us/sample - loss: 1.7125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2159c5824a8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=20,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6276233267731899199\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_441_RNN_and_LSTM.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "U4-S2-NN (Python3)",
   "language": "python",
   "name": "u4-s2-nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
